{
    "summary": "SingularGPT is an open-source project combining AI vision, automation (ZexUI), and GPT for device automation via NLP instructions. It features elements detection, text detection, headless x11 server support, lightweight presets, and encourages documentation contribution.",
    "details": [
        {
            "comment": "SingularGPT is an open source project that automates device tasks using ChatGPT and GPT-4. It allows users to issue simple text-based queries to instruct their devices. Demo available, use in Google Colab with a GPU, follow instructions carefully.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/README.md\":1-34",
            "content": "**SingularGPT** is a open source project that automates your device using ChatGPT & GPT-4.\nWith \ud83d\ude80 **SingularGPT** you can easily instruct your device with simple text based queries.\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abhiprojectz/SingularGPT/blob/master/SGPT_Quickstart.ipynb)\n> For example: \nLet's say you need to click on button that have a text as 'File' just say it: \n**Query:** Hey, please click on the item with text File.\nIt will perform the action by processing your query, turning them to its understandable instructions and execute them.\n---\n# :star2: Demo \nhttps://user-images.githubusercontent.com/64596494/230719544-a9bee6f2-4158-4784-b0ed-260bea7be067.mp4\n---\n# :star2: How to Use ?\nYou may just run it in google colab with a GPU.\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abhiprojectz/SingularGPT/blob/master/SGPT_Quickstart.ipynb)\n**Follow these steps carefully**"
        },
        {
            "comment": "This code provides a quickstart guide for using the SingularGPT bot. It explains how to install dependencies, set up environment variables, and run the main script with prompts or instructions from a file. The last line suggests checking out the bot on Poe for visualization.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/README.md\":36-86",
            "content": "- 1. Install all the requirements\n```\npip install -r requirements.txt\n```\nMake sure that you run this command in the same directory where the `requirements.txt` file is located.\n- 2. If you are in linux then install below libs\n```sh \n!sudo apt-get install xvfb xorg xserver-xorg scrot imagemagick x11-utils xdotool\n```\n- 3. Create a .env file and place your OPENAI_API and change your platform name in `config/CONFIG.py`\nif you are on linux set as: `_PLATFORM` as linux [By default is `windows`]\n- 4. Run this file `main.py` by passing your query.\n```py\npython main.py\n```\n- 5. Use `SingularGPT` bot if you are stuck or raise a issue\n- 6. Make sure your instructions are in `script.py` file.\n## :star2: Quickstart\nCreate a `.env` file with `OPENAI_API` and place your openai_api api there or pass as environment variable.\nPut automation scripts in `script.py` and run it.\nWrite your prompt query in `Prompts/prompts.txt` file or,\npass as a string in the `main.py` file.\n```py\n# Run the main script.\npython main.py\n```\n---\n**To visualize this see this bot on Poe**"
        },
        {
            "comment": "ZexUI is a standalone library for GUI automation that utilizes image processing techniques. It allows locating and performing actions on elements based on their positions relative to other elements. The code snippet demonstrates using the \"text\" method to locate an element and clicking it, as well as finding the leftmost element near the target element and performing an action on it.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/README.md\":88-139",
            "content": "![](https://user-images.githubusercontent.com/64596494/230727123-b01d6607-9f08-4abe-ae00-bda1eacbc5bf.PNG)\n![djlkdj](https://user-images.githubusercontent.com/64596494/230751800-1100bfa5-f9a7-4971-9224-6f0c442b5df1.PNG)\n---\n# :star2: How it locates element ?\nThe old way using X_PATH or CSS/JS Selectors or by just co-ordinates.\n```py\nelement_xpath = driver.find_element(By.XPATH, \"//a[@href='/login']\")\nelement_xpath.click()\n# or \nelement_css = driver.find_element(By.CSS_SELECTOR, \"button.btn-primary\")\nelement_css.click()\n```\n> No, it uses the new GUI element detection techniques.\nNopes ! \n```py\nzex.text('Menu').click()\nzex.text('Edit').FindLeftOf().click() # Used to locate the element that is just left side of the target element.\n```\n---\n**Locate and perform actions to the element that is left or right or even the most nearest element to it.**\nZexUI is a standalone library that uses image processing techniques for GUI automation.\n---\n#  :star2: Automations lib apis\nHere are some methods and thier usage.\nSure! Here are the descriptions for each method:"
        },
        {
            "comment": "This code describes various methods used for locating elements on a webpage based on different criteria such as text content, image path, and relative positions. These methods can be useful in web scraping, form filling, and interacting with web applications programmatically.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/README.md\":141-157",
            "content": "- `text()`: This method is used to locate a text element on the webpage based on the text content provided in the query.\n- `textRegex()`: This method is used to locate a text element on the webpage based on a regular expression provided in the query.\n- `textContains()`: This method is used to locate a text element on the webpage that contains a specific word provided in the query.\n- `image()`: This method is used to locate an image element on the webpage based on the image path provided in the query.\n- `findLeftOf()`: This method is used to locate an element that is to the left of the text/image provided in the query.\n- `findRightOf()`: This method is used to locate an element that is to the right of the text/image provided in the query.\n- `findTopOf()`: This method is used to locate an element that is above the text/image provided in the query.\n- `findBottomOf()`: This method is used to locate an element that is below the text/image provided in the query.\n- `findNearestTo()`: This method is used to locate the element that is nearest to the text/image provided in the query."
        },
        {
            "comment": "This code describes methods for interacting with a webpage, such as clicking, moving the mouse, and scrolling. The project aims to convert natural language queries into automation scripts that can be used to achieve tasks. SingularGPT processes screen data and generates commands accordingly. It recognizes content on screens and headless servers using x11.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/README.md\":159-192",
            "content": "- `click()`: This method is used to click on the element that is located using the text/image or any other method.\n- `mouseMove()`: This method is used to move the mouse to the element that is located using the text/image or any other method.\n- `scroll_up()`: This method is used to scroll up the webpage.\n- `scroll_down()`: This method is used to scroll down the webpage.\n- `scroll_left()`: This method is used to scroll left on the webpage.\n- `scroll_right()`: This method is used to scroll right on the webpage.\n... More are on the docs. \n**This is what this project aims and tries to achieve the same.**\n :star2: So, here's how the things works under the hood:\n+ Converts Natural language query to automation scripts that further can be used to achieve the task \n+ SingularGPT Process your screen, gets the required data what's being asked.\n+ Generates commands to achieve the task.\n---\n# :star2: What SingularGPT can do ?\n+ Recognize what's on your screen \n+ Even what's on your headless server using x11\n+ Can internally process them."
        },
        {
            "comment": "The code describes a project utilizing AI-based vision, automation (ZexUI), and GPT to achieve device automation through NLP instructions. It includes features like no crawling mechanism, elements detection, text detection, components detection based on estimates, works headless on x11 server, lightweight presets, and encourages leaving a star and helping with project documentation.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/README.md\":194-232",
            "content": "+ Build automations scripts by its own\n+ Automates your device\n---\n# :star2: Breakdown of the project\nThis projects is made possible with the help of various fields in computer science such as AI based vision, Custom libs, device automation and internal logic processing using the latest ChatGPT & GPT-4.\nIn short:\nAI computer vision + Automation (ZexUI) + GPT\n---\n# :star2: Features \n+ No crawling mechanism\n+ Elements detection\n+ Text detection\n+ Components detection based on estimates\n+ Automate your device using NLP instructions\n+ Adds-on in a very lightweight presets\n+ Works even headless on a x11 server\n# :star2: Help \nConsidering leaving a star.\n# :star2: Docs\nHelp in writing the docs for the project.\n---"
        }
    ]
}