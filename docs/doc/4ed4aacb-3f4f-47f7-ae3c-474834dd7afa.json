{
    "summary": "The code uses OpenCV for image processing, OCR, and object detection; includes functions for error handling, displaying images, detecting objects, drawing shapes, storing information, and mouse/scrolling control.",
    "details": [
        {
            "comment": "Code imports necessary libraries and defines a class for the ZexUI automation library. It captures screenshots of the current screen and saves them to the specified path. The capture function is used to take screenshots.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":0-37",
            "content": "# from google.colab.patches import cv2_imshow\nimport re \nimport cv2\nimport subprocess\nimport json \nimport numpy as np \nfrom vision.vision_utils import detect_component\nfrom zexui_lib.base_functions import * \nfrom time import sleep \nfrom config.CONFIG import _PLATFORM\n\"\"\"\nMain automation library that automates the device level stuffs.\n\"\"\"\nif _PLATFORM == 'windows':\n    from .py_gui_commands import * \nelif _PLATFORM == 'linux':\n    from .x11_commands import *\nclass ZexUI(object):\n    \"\"\"\n    Main ZEXUI library for the automation stuff.\n    \"\"\"\n    def __init__(self):\n        # This variable stores the path of the captured image in PNG format.\n        self.capture_png = 'data/input/curr_img.png'\n        self.img_path = \"\"    \n        self.cords = \"\"       \n        self.img_chunk = \"\"   \n        self._type_elm = \"\"   \n    def capture(self):\n        \"\"\"\n        This function captures the screenshot of the current screen and saves it\n        to the path specified by self.capture_png variable.\n        \"\"\"\n        capture(self.capture_png)"
        },
        {
            "comment": "This function preprocesses the image by reading it using OpenCV, converting to grayscale, applying binary inverse thresholding, and then calling detect_component with appropriate arguments. The input is an image path, and it returns the object of the class after preprocessing.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":38-65",
            "content": "        self.img_path = self.capture_png\n    def _preprocess_img(self, _img):\n        \"\"\"\n        This function preprocesses the image by:\n        - Reading the image using OpenCV (cv2).\n        - Converting the image to grayscale.\n        - Applying thresholding to the grayscale image using Binary Inverse Thresholding.\n        - Calling `detect_component` function with input_path_img, output_root, is_ocr, and is_merge arguments,\n          and returning self.\n        Parameters:\n        _img (str): The path of the image which is to be preprocessed.\n        Returns:\n        self: The object of the class.\n        \"\"\"\n        img = cv2.imread(_img)\n        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY_INV)\n        # input_path_img = 'data/input/tx_5.PNG'\n        output_root = 'data/output'\n        # detect_component(input_path_img, output_root, is_ocr=True, is_ip=False, is_merge=False)\n        return self\n    def text(self, text):\n        \"\"\""
        },
        {
            "comment": "This code finds the center of a bounding box around a given text in an image. It first captures the latest screenshot, then uses OCR to detect text components. The JSON data is read and a white image is created. Rectangles and points are drawn on the image for each detected text component, and if a matching text is found, its bounding box center coordinates are returned.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":66-94",
            "content": "        Finds the center of the bounding box around a given text in an image.\n        Args:\n            img_path (str): Path to the input image.\n            text (str): The text to search for.\n        Returns:\n            Tuple[int, int]: The (x, y) coordinates of the center of the bounding box.\n        \"\"\"\n        # Getting latest screenshot of the screen/display\n        self.capture()\n        # Detect text components in the image using OCR.\n        input_path_img = self.img_path\n        output_root = 'data/output'\n        detect_component(input_path_img, output_root, _is_text=True, _is_element=False)\n        # Read JSON data\n        with open('data/output/ocr/curr_img.json', 'r') as f:\n            data = json.load(f)\n        # Create a white image\n        img = 255 * np.ones((200, 1900, 3), dtype=np.uint8)\n        _res = None\n        # Draw rectangles and points on the image\n        for compo in data['texts']:\n            # Removes anyn trailings spaces from the text\n            if compo['content'].lstrip() == text:"
        },
        {
            "comment": "This code snippet is part of a computer vision application, possibly related to OCR (Optical Character Recognition) or image analysis. It detects and extracts text from an input image. The 'compo' dictionary contains parameters such as column_min, row_min, etc., which are used to identify text regions in the image. A rectangle is drawn around the detected text using cv2.rectangle function, and a circle is drawn at the center of the text using cv2.circle function. The code handles the case when no text is detected (cords == None) by raising an exception. Finally, it uses self.img_path to process the image and returns a result.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":95-121",
            "content": "                pt1 = (compo['column_min'], compo['row_min'])\n                pt2 = (compo['column_max'], compo['row_max'])\n                color = (0, 0, 255)  # BGR color code for red\n                thickness = 2\n                # img = cv2.rectangle(img, pt1, pt2, color, thickness)\n                center = ((compo['column_min'] + compo['column_max']) // 2,\n                        (compo['row_min'] + compo['row_max']) // 2)\n                radius = 2\n                # img = cv2.circle(img, center, radius, color, thickness=-1)\n                # print(center)\n                _res = center\n        if _res == None:\n            raise ValueError(f\"The {text} is not present in the current component\")\n        # Display the image\n        # cv2_imshow(img)\n        self.cords = _res\n        self._type_elm = 'texts'\n        return self\n    def textRegex(self, text_regex):\n        \"\"\"\n        This function performs text detection and recognition on the processed image\n        using the path specified in self.img_path. It uses `detect_component` function"
        },
        {
            "comment": "This code captures the latest screenshot, detects text components using OCR, reads JSON data, creates a white image, and draws rectangles and points on the image for matching text components. It does not use the provided text_regex parameter.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":122-151",
            "content": "        with input_path_img, output_root, is_ocr, and is_merge arguments.\n        Parameters:\n        text_regex (str): The text recognised by OCR. It is not used in the code provided.\n        Returns:\n        Text co-ordinates instance.\n        \"\"\"\n        # Getting latest screenshot of the screen/display\n        self.capture()\n        input_path_img = self.img_path\n        output_root = 'data/output'\n        detect_component(input_path_img, output_root, _is_text=True, _is_element=False)\n        # Read JSON data\n        with open('data/output/ocr/curr_img.json', 'r') as f:\n            data = json.load(f)\n        # Create a white image\n        img = 255 * np.ones((200, 1900, 3), dtype=np.uint8)\n        _res = None\n        # Draw rectangles and points on the image\n        for compo in data['texts']:\n            if re.search(text_regex, compo['content'].lstrip()):\n                pt1 = (compo['column_min'], compo['row_min'])\n                pt2 = (compo['column_max'], compo['row_max'])\n                color = (0, 0, 255)  # BGR color code for red"
        },
        {
            "comment": "The code snippet initializes variables for drawing a rectangle and circle on an image, calculates the center of the component, checks if the component is present or not, displays the image, and defines a function to check whether the output elements contain the given text.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":152-181",
            "content": "                thickness = 2\n                # img = cv2.rectangle(img, pt1, pt2, color, thickness)\n                center = ((compo['column_min'] + compo['column_max']) // 2,\n                        (compo['row_min'] + compo['row_max']) // 2)\n                radius = 2\n                # img = cv2.circle(img, center, radius, color, thickness=-1)\n                # print(center)\n                _res = center\n        if _res == None:\n            raise ValueError(f\"The {text_regex} is not present in the current component\")\n        # Display the image\n        # cv2_imshow(img)\n        self.cords = _res\n        self._type_elm = 'texts'\n        return self\n    def textContains(self, text):\n        \"\"\"\n        This function checks whether the output elements contains the text or not.\n        \"\"\"\n        # Getting latest screenshot of the screen/display\n        self.capture()\n        input_path_img = self.img_path\n        output_root = 'data/output'\n        detect_component(input_path_img, output_root, _is_text=True, _is_element=False)"
        },
        {
            "comment": "This code reads a JSON file containing text components and checks if a specific text is present in one of them. It then draws rectangles around the found text and adds a circle at its center on an image, unless the specified text is not found in any component, in which case it raises a ValueError.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":183-207",
            "content": "        # Read JSON data\n        with open('/content/SingularGPT/data/output/ocr/curr_img.json', 'r') as f:\n            data = json.load(f)\n        # Create a white image\n        img = 255 * np.ones((200, 1900, 3), dtype=np.uint8)\n        _res = None\n        # Draw rectangles and points on the image\n        for compo in data['texts']:\n            if text in compo['content'].lstrip():\n                pt1 = (compo['column_min'], compo['row_min'])\n                pt2 = (compo['column_max'], compo['row_max'])\n                color = (0, 0, 255)  # BGR color code for red\n                thickness = 2\n                # img = cv2.rectangle(img, pt1, pt2, color, thickness)\n                center = ((compo['column_min'] + compo['column_max']) // 2,\n                        (compo['row_min'] + compo['row_max']) // 2)\n                radius = 2\n                # img = cv2.circle(img, center, radius, color, thickness=-1)\n                # print(center)\n                _res = center\n        if _res == None:\n            raise ValueError(f\"The {text} is not present in the current component\")"
        },
        {
            "comment": "This code snippet finds the location of a target image on the main image and calculates its center coordinates. It saves these coordinates in self.cords and sets the type of element as 'compos'. The code does not perform any image display or save operations.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":209-236",
            "content": "        # Display the image\n        # cv2_imshow(img)\n        self.cords = _res\n        self._type_elm = 'texts'\n        return self\n    def image(self, target_img):\n        \"\"\"\n        This function takes an input target image and finds its location on the main image using the find_location_of_img_obj function. \n        It then calculates the center coordinates of the target image using its height and width. \n        The coordinates are saved in self.cords and the type of element is saved in _type_elm as compos. \n        \"\"\"\n        # input_path_img = self.img_path\n        # output_root = 'data/output'\n        # detect_component(input_path_img, output_root, is_ocr=False, is_ip=True, is_merge=False)\n        self.capture()\n        _x = find_location_of_img_obj(self.img_path, target_img)\n        _img = cv2.imread(target_img)\n        height, width, c = _img.shape\n        # center_coordinates = (x + int(width/2), y + int(height/2))    \n        # radius = 2\n        # color = (0, 78, 255)\n        # thickness = 2\n        # cv2.circle(cv2.imread(self.img_path), center_coordinates, radius, color, thickness)"
        },
        {
            "comment": "This code defines a class with functions for image processing and object detection using OpenCV and JSON. The `cv2_imshow` function displays an image, while `get_all_objects` returns a list of detected objects in JSON format based on the specified element type (texts or compos). The function reads existing JSON files based on the provided image path and output root directory.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":237-268",
            "content": "        # cv2_imshow(cv2.imread(self.img_path))\n        self.cords = (_x[0] + int(width/2), _x[1] + int(height/2))\n        self._type_elm = 'compos'\n        return self\n    def get_all_objects(self, _type_elm):\n        \"\"\"\n        Returns the list of all the objects that are so far detected and saved in the ocr results json format.\n        \"\"\"\n        if _type_elm == 'texts':\n            _el_type = 'texts'\n            with open('data/output/ocr/curr_img.json', 'r') as f:\n                data = json.load(f)\n        else:\n            _el_type = 'compos'\n            input_path_img = self.img_path\n            output_root = 'data/output'\n            detect_component(input_path_img, output_root, _is_text=False, _is_element=True)\n            with open('data/output/element/curr_img.json', 'r') as f:\n                data = json.load(f)  \n        objects = []\n        objs = []\n        # Draw rectangles and points on the image\n        for compo in data[_el_type]:\n            pt1 = (compo['column_min'], compo['row_min'])"
        },
        {
            "comment": "The code defines a function that takes coordinates of an object and its dimensions, and draws a rectangle around it with the bottom-left corner as pt1, and a circle at its center. It also stores the objects' centers and their information in separate lists. The second function finds the object to the left of a target object based on its coordinates and the list of objects obtained from another method call.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":269-291",
            "content": "            pt2 = (compo['column_max'], compo['row_max'])\n            color = (0, 0, 255)  # BGR color code for red\n            thickness = 2\n            radius = 2\n            # img = cv2.rectangle(img, pt1, pt2, color, thickness)\n            center = ((compo['column_min'] + compo['column_max']) // 2,\n                    (compo['row_min'] + compo['row_max']) // 2)\n            # img = cv2.circle(img, center, radius, color, thickness=-1)\n            objects.append(center)\n            objs.append(compo)\n        return objects, objs\n    def findLeftOf(self):\n        \"\"\"\n        This function finds the object present to the left of the target object based on\n        the coordinates of the target object `cords` and the list of objects obtained after\n        calling the `get_all_objects` method with `self._type_elm` as argument.\n        It then returns the object present to the left of the target object.\n        Returns:\n        self (object): The object present to the left of the target object returned by this method."
        },
        {
            "comment": "This code snippet retrieves all objects and their labels of type element, then finds the target object based on given coordinates. It determines the object below the target, gets its index, retrieves the object to the left of the target, updates the target's coordinates with the bottom object's, and finally returns the left object. The `findRightOf` function seeks the right object based on the target's coordinates and a list of objects from get_all_objects(self._type_elm).",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":292-318",
            "content": "        \"\"\"\n        # Extract all objects and object labels of type element\n        objects, objs = self.get_all_objects(self._type_elm)\n        # Find the target object for which we're searching for the object to the left\n        target_obj = self.cords\n        # Find the object present to the bottom of the target object\n        x = find_obj_to_bottom_of_target_obj(target_obj, objects)\n        # Get the index of the object present to the bottom of the target object\n        x_ind = objects.index(x)\n        # Get the object present to the left of the target object\n        _compo = objs[x_ind]\n        # Update the coordinates of the target object to the bottom object coordinates\n        self.cords = x\n        # Return the object present to the left of the target object\n        return self\n    def findRightOf(self):\n        \"\"\"\n        This function finds the object present to the right of the target object based on\n        the coordinates of the target object `cords` and the list of objects obtained after\n        calling the `get_all_objects` method with `self._type_elm` as argument."
        },
        {
            "comment": "The function searches for an object to the right of a specified target object and returns the found object. It uses get_all_objects() to extract objects and their labels, then finds the target object using coordinates. It identifies the object to the right by calling find_obj_to_right_of_target_obj(), retrieves its index, gets the corresponding object from objs list, updates the target object's coordinates with the found object's coordinates, and finally returns the found object.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":319-347",
            "content": "        It then returns the object present to the right of the target object.\n        Returns:\n        self (object): The object present to the right of the target object returned by this method.\n        \"\"\"\n        # Extract all objects and object labels of type element\n        objects, objs = self.get_all_objects(self._type_elm)\n        # Find the target object for which we're searching for the object to the right\n        target_obj = self.cords\n        # Find the object present to the right of the target object\n        x = find_obj_to_right_of_target_obj(target_obj, objects)\n        # Get the index of the object present to the right of the target object\n        x_ind = objects.index(x)\n        # Get the object present to the right of the target object\n        _compo = objs[x_ind]\n        # Update the coordinates of the target object to the right object coordinates\n        self.cords = x\n        # Return the object present to the right of the target object\n        return self\n    def findTopOf(self):\n        \"\"\""
        },
        {
            "comment": "This function finds the object at the top of a target object by extracting all objects and labels, then locates the target object, finds the object on top of it, gets its index, and returns the object.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":348-369",
            "content": "        This function finds the object present at the top of the target object based on\n        the coordinates of the target object `cords` and the list of objects obtained after\n        calling the `get_all_objects` method with `self._type_elm` as argument.\n        It then returns the object present at the top of the target object.\n        Returns:\n        self (object): The object present at the top of the target object returned by this method.\n        \"\"\"\n        # Extract all objects and object labels of type element\n        objects, objs = self.get_all_objects(self._type_elm)\n        # Find the target object for which we're searching for the object at the top\n        target_obj = self.cords\n        # Find the object present at the top of the target object\n        x = find_obj_to_top_of_target_obj(target_obj, objects)\n        # Get the index of the object present at the top of the target object\n        x_ind = objects.index(x)\n        # Get the object present at the top of the target object\n        _compo = objs[x_ind]"
        },
        {
            "comment": "This function updates the coordinates of the target object to the top object's coordinates and returns the object present at the bottom of the target object based on its coordinates and a list of objects.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":371-394",
            "content": "        # Update the coordinates of the target object to the top object coordinates\n        self.cords = x\n        # Return the object present at the top of the target object\n        return self\n    def findBottomOf(self):\n        \"\"\"\n        This function finds the object present at the bottom of the target object based on\n        the coordinates of the target object `cords` and the list of objects obtained after\n        calling the `get_all_objects` method with `self._type_elm` as argument.\n        It then returns the object present at the bottom of the target object.\n        Returns:\n        self (object): The object present at the bottom of the target object returned by this method.\n        \"\"\"\n        # Extract all objects and object labels of type element\n        objects, objs = self.get_all_objects(self._type_elm)\n        # Find the target object for which we're searching for the object at the bottom\n        target_obj = self.cords\n        # Find the object present at the bottom of the target object"
        },
        {
            "comment": "This code snippet finds the object located at the bottom of another object and updates the coordinates of the target object to match those of the bottom object. It then returns the object found. The code also includes a function for finding the nearest point to the current target point using Euclidean distance, which could be utilized in further functionality.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":395-428",
            "content": "        x = find_obj_to_bottom_of_target_obj(target_obj, objects)\n        # Get the index of the object present at the bottom of the target object\n        x_ind = objects.index(x)\n        # Get the object present at the bottom of the target object\n        _compo = objs[x_ind]\n        # Update the coordinates of the target object to the bottom object coordinates\n        self.cords = x\n        # Return the object present at the bottom of the target object\n        return self\n  # Todo\n  # def or(self):\n  #   pass \n    def findNearestTo(self):\n        objects, objs = self.get_all_objects(self._type_elm)\n        # Define the list of coordinates\n        coords = objects\n        # Define the target point\n        target_point = self.cords\n        # Calculate the Euclidean distance between the target point and all other points\n        distances = [np.linalg.norm(np.array(coord) - np.array(target_point)) for coord in coords]\n        # Find the index of the nearest point\n        nearest_idx = np.argmin(distances)\n        # Get the nearest point"
        },
        {
            "comment": "This code is creating a white image, drawing red circles around the nearest point and green circles around other points, displaying the image, and printing the coordinates of the nearest point. It also provides methods for writing text with delay and clicking on target objects using their coordinates.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":429-462",
            "content": "        nearest_point = coords[nearest_idx]\n        # # Create a white image\n        # img = np.zeros((512, 800, 3), np.uint8)\n        # img.fill(255)\n        # # Draw a red circle around the nearest point\n        # cv2.circle(img, nearest_point, 10, (0, 0, 255), -1)\n        # # Draw green circles around all other points\n        # for coord in coords:\n        #     if coord != nearest_point:\n        #         cv2.circle(img, coord, 10, (0, 255, 0), -1)\n        # Display the image\n        # cv2.imshow('image', img)\n        # Print the coordinates of the nearest point\n        print(\"Nearest point coordinates:\", nearest_point)\n        self.cords = nearest_point\n        return self\n    def write(self, text):\n        delay = True\n        write(text, delay)\n    def click(self):\n        \"\"\"\n        This function gets the x and y coordinates of the target object `cords` and calls the `click_one` function\n        by passing the x and y coordinates as arguments.\n        \"\"\"\n        # Get the x and y coordinates of the target object"
        },
        {
            "comment": "The code contains two functions, `mouseMoveTo` and `mouseMove`. The `mouseMoveTo` function takes in x and y coordinates as parameters and moves the mouse cursor to that specified location. The `mouseMove` function finds the x and y coordinates of a target object (presumably using `self.cords`) and moves the mouse cursor to those coordinates without any additional parameters.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":463-499",
            "content": "        x = self.cords[0]\n        y = self.cords[1]\n        sleep(1)\n        # Print the x and y coordinates of the target object\n        print(x, y)\n        # Call the `click_one` function by passing the x and y coordinates as arguments\n        click_one(x, y)\n    def mouseMoveTo(self, x, y):\n        \"\"\"\n        This function moves the mouse cursor to the provided x and y coordinates.\n        Parameters:\n        x (int): The x-coordinate to which the mouse cursor has to be moved.\n        y (int): The y-coordinate to which the mouse cursor has to be moved.\n        \"\"\"\n        # Move the mouse cursor to the provided x and y coordinates\n        mouse_move(x, y)\n    def mouseMove(self):\n        \"\"\"\n        This function moves the mouse cursor to the x and y coordinates of the target object.\n        Parameters:\n        None\n        Returns:\n        None\n        \"\"\"\n        # Get the x and y coordinates of the target object\n        x, y = self.cords[0], self.cords[1]\n        # Move the mouse cursor to the x and y coordinates of the target object"
        },
        {
            "comment": "The code snippet defines various mouse and scroll functions, including move, wait, up/down scrolling in all directions. The mouseToggleUp and mouseToggleDown functions obtain the target object's coordinates and call respective functions with those coordinates.",
            "location": "\"/media/root/Toshiba XG3/works/SingularGPT/docs/src/zexui_lib/zexui.py\":500-525",
            "content": "        mouse_move(x, y)\n    def wait(self, x):\n        wait(x)\n    def scroll_up(self, x):\n        scroll_up(x)\n    def scroll_down(self, x):\n        scroll_down(x)\n    def scroll_left(self, x):\n        scroll_left(self, x)\n    def scroll_right(self, x):\n        scroll_right(self, x)\n    def mouseToggleUp(self):\n        # Get the x and y coordinates of the target object\n        x, y = self.cords[0], self.cords[1]\n        mouseToggleUp(x, y)\n    def mouseToggleDown(self):\n        # Get the x and y coordinates of the target object\n        x, y = self.cords[0], self.cords[1]\n        mouseToggleDown(x, y)"
        }
    ]
}