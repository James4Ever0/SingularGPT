{
    "100": {
        "file_id": 7,
        "content": "            return None\n    def extract_line_area(line, start_idx, flag='v'):\n        for e, l in enumerate(line):\n            if flag == 'v':\n                map_line[start_idx + e, l[0]:l[1]] = binary[start_idx + e, l[0]:l[1]]\n    map_line = np.zeros(binary.shape[:2], dtype=np.uint8)\n    cv2.imshow('binary', binary)\n    width = binary.shape[1]\n    start_row = -1\n    line_area = []\n    for i, row in enumerate(binary):\n        line_v = check_continuous_line(row, width)\n        if line_v is not None:\n            # new line\n            if start_row == -1:\n                start_row = i\n                line_area = []\n            line_area.append(line_v)\n        else:\n            # checking line\n            if start_row != -1:\n                if i - start_row < max_line_thickness:\n                    # binary[start_row: i] = 0\n                    # map_line[start_row: i] = binary[start_row: i]\n                    print(line_area, start_row, i)\n                    extract_line_area(line_area, start_row)\n                start_row = -1",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:319-348"
    },
    "101": {
        "file_id": 7,
        "content": "This function iterates through each row of the binary image. If it detects a continuous line, it stores the line area in `line_area`. If it detects another line before the previous one ends (within `max_line_thickness` pixels), it calls `extract_line_area()` to extract and handle the line area. This process continues until all lines are processed or no more lines are detected.",
        "type": "comment"
    },
    "102": {
        "file_id": 7,
        "content": "    height = binary.shape[0]\n    start_col = -1\n    for i in range(width):\n        col = binary[:, i]\n        line_h = check_continuous_line(col, height)\n        if line_h is not None:\n            # new line\n            if start_col == -1:\n                start_col = i\n        else:\n            # checking line\n            if start_col != -1:\n                if i - start_col < max_line_thickness:\n                    # binary[:, start_col: i] = 0\n                    map_line[:, start_col: i] = binary[:, start_col: i]\n                start_col = -1\n    binary -= map_line\n    if show:\n        cv2.imshow('no-line', binary)\n        cv2.imshow('lines', map_line)\n        cv2.waitKey()\ndef rm_line(binary,\n            max_line_thickness=C.THRESHOLD_LINE_THICKNESS,\n            min_line_length_ratio=C.THRESHOLD_LINE_MIN_LENGTH,\n            show=False, wait_key=0):\n    def is_valid_line(line):\n        line_length = 0\n        line_gap = 0\n        for j in line:\n            if j > 0:\n                if line_gap > 5:\n                    return False",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:350-385"
    },
    "103": {
        "file_id": 7,
        "content": "This code detects and removes horizontal lines from an image using binary thresholding. It iterates through each column, identifies continuous lines, and marks them in a separate map. If the line thickness is within the maximum limit, it replaces the binary image's corresponding columns with zeros. Finally, it displays the original image (binary) and the one with removed lines (map_line).",
        "type": "comment"
    },
    "104": {
        "file_id": 7,
        "content": "                line_length += 1\n                line_gap = 0\n            elif line_length > 0:\n                line_gap += 1\n        if line_length / width > 0.95:\n            return True\n        return False\n    height, width = binary.shape[:2]\n    board = np.zeros(binary.shape[:2], dtype=np.uint8)\n    start_row, end_row = -1, -1\n    check_line = False\n    check_gap = False\n    for i, row in enumerate(binary):\n        # line_ratio = (sum(row) / 255) / width\n        # if line_ratio > 0.9:\n        if is_valid_line(row):\n            # new start: if it is checking a new line, mark this row as start\n            if not check_line:\n                start_row = i\n                check_line = True\n        else:\n            # end the line\n            if check_line:\n                # thin enough to be a line, then start checking gap\n                if i - start_row < max_line_thickness:\n                    end_row = i\n                    check_gap = True\n                else:\n                    start_row, end_row = -1, -1\n                check_line = False",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:386-417"
    },
    "105": {
        "file_id": 7,
        "content": "The code detects lines in a binary image and determines if they exceed 0.95 of the image's width to classify as valid lines. It also checks line thickness and gaps between lines. The maximum line thickness is considered, and the code switches between checking lines and gaps within a loop over each row of the binary image. The shape and type of the binary image are assigned to the board array, which is initialized with zeros using numpy's zeros function. Start and end rows for valid lines and potential gaps are tracked, along with boolean flags for line and gap checking states.",
        "type": "comment"
    },
    "106": {
        "file_id": 7,
        "content": "        # check gap\n        if check_gap and i - end_row > max_line_thickness:\n            binary[start_row: end_row] = 0\n            start_row, end_row = -1, -1\n            check_line = False\n            check_gap = False\n    if (check_line and (height - start_row) < max_line_thickness) or check_gap:\n        binary[start_row: end_row] = 0\n    if show:\n        cv2.imshow('no-line binary', binary)\n        if wait_key is not None:\n            cv2.waitKey(wait_key)\n        if wait_key == 0:\n            cv2.destroyWindow('no-line binary')\ndef rm_noise_compos(compos):\n    compos_new = []\n    for compo in compos:\n        if compo.category == 'Noise':\n            continue\n        compos_new.append(compo)\n    return compos_new\ndef rm_noise_in_large_img(compos, org,\n                      max_compo_scale=C.THRESHOLD_COMPO_MAX_SCALE):\n    row, column = org.shape[:2]\n    remain = np.full(len(compos), True)\n    new_compos = []\n    for compo in compos:\n        if compo.category == 'Image':\n            for i in compo.contain:\n                remain[i] = False",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:418-453"
    },
    "107": {
        "file_id": 7,
        "content": "This code is responsible for image processing, specifically removing noise components and creating binary images. It includes functions to remove noise composites, identify and delete noisy regions in large images, and display the resulting binary image. The max_line_thickness and max_compo_scale parameters control the threshold values for line detection and composition removal respectively.",
        "type": "comment"
    },
    "108": {
        "file_id": 7,
        "content": "    for i in range(len(remain)):\n        if remain[i]:\n            new_compos.append(compos[i])\n    return new_compos\ndef detect_compos_in_img(compos, binary, org, max_compo_scale=C.THRESHOLD_COMPO_MAX_SCALE, show=False):\n    compos_new = []\n    row, column = binary.shape[:2]\n    for compo in compos:\n        if compo.category == 'Image':\n            compo.compo_update_bbox_area()\n            # org_clip = compo.compo_clipping(org)\n            # bin_clip = pre.binarization(org_clip, show=show)\n            bin_clip = compo.compo_clipping(binary)\n            bin_clip = pre.reverse_binary(bin_clip, show=show)\n            compos_rec, compos_nonrec = component_detection(bin_clip, test=False, step_h=10, step_v=10, rec_detect=True)\n            for compo_rec in compos_rec:\n                compo_rec.compo_relative_position(compo.bbox.col_min, compo.bbox.row_min)\n                if compo_rec.bbox_area / compo.bbox_area < 0.8 and compo_rec.bbox.height > 20 and compo_rec.bbox.width > 20:\n                    compos_new.append(compo_rec)",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:454-475"
    },
    "109": {
        "file_id": 7,
        "content": "The function `detect_compos_in_img` takes in a list of compositions, a binary image, an organization (org) object, maximum composition scale, and optionally a boolean for showing images. It iterates through each composition and if the category is 'Image', it updates the bounding box area and clips the binary image to the composition's bounding box. It then detects components within the clipped image and appends non-recording component records to the `compos_new` list, if certain conditions are met (bbox area ratio, height, width). Finally, it returns the updated list of compositions.",
        "type": "comment"
    },
    "110": {
        "file_id": 7,
        "content": "                    # draw.draw_bounding_box(org, [compo_rec], show=True)\n            # compos_inner = component_detection(bin_clip, rec_detect=False)\n            # for compo_inner in compos_inner:\n            #     compo_inner.compo_relative_position(compo.bbox.col_min, compo.bbox.row_min)\n            #     draw.draw_bounding_box(org, [compo_inner], show=True)\n            #     if compo_inner.bbox_area / compo.bbox_area < 0.8:\n            #         compos_new.append(compo_inner)\n    compos += compos_new\ndef compo_filter(compos, min_area, img_shape):\n    max_height = img_shape[0] * 0.8\n    compos_new = []\n    for compo in compos:\n        if compo.area < min_area:\n            continue\n        if compo.height > max_height:\n            continue\n        ratio_h = compo.width / compo.height\n        ratio_w = compo.height / compo.width\n        if ratio_h > 50 or ratio_w > 40 or \\\n                (min(compo.height, compo.width) < 8 and max(ratio_h, ratio_w) > 10):\n            continue\n        compos_new.append(compo)",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:476-500"
    },
    "111": {
        "file_id": 7,
        "content": "This code is part of a component detection function in the \"ip_detection.py\" file. It filters out components from a list based on certain criteria such as minimum area, maximum height, aspect ratio, and size. The filtered components are added to a new list called \"compos_new\", which is then appended to the original list.",
        "type": "comment"
    },
    "112": {
        "file_id": 7,
        "content": "    return compos_new\ndef is_block(clip, thread=0.15):\n    '''\n    Block is a rectangle border enclosing a group of compos (consider it as a wireframe)\n    Check if a compo is block by checking if the inner side of its border is blank\n    '''\n    side = 4  # scan 4 lines inner forward each border\n    # top border - scan top down\n    blank_count = 0\n    for i in range(1, 5):\n        if sum(clip[side + i]) / 255 > thread * clip.shape[1]:\n            blank_count += 1\n    if blank_count > 2: return False\n    # left border - scan left to right\n    blank_count = 0\n    for i in range(1, 5):\n        if sum(clip[:, side + i]) / 255 > thread * clip.shape[0]:\n            blank_count += 1\n    if blank_count > 2: return False\n    side = -4\n    # bottom border - scan bottom up\n    blank_count = 0\n    for i in range(-1, -5, -1):\n        if sum(clip[side + i]) / 255 > thread * clip.shape[1]:\n            blank_count += 1\n    if blank_count > 2: return False\n    # right border - scan right to left\n    blank_count = 0\n    for i in range(-1, -5, -1):",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:501-532"
    },
    "113": {
        "file_id": 7,
        "content": "The code checks if a compo is a block by examining the inner sides of its border. It scans four lines inside each border, top down for the top border, left to right for the left border, bottom up for the bottom border, and right to left for the right border. If any of these scans detect more than two blank lines, the compo is not considered a block.",
        "type": "comment"
    },
    "114": {
        "file_id": 7,
        "content": "        if sum(clip[:, side + i]) / 255 > thread * clip.shape[0]:\n            blank_count += 1\n    if blank_count > 2: return False\n    return True\ndef compo_block_recognition(binary, compos, block_side_length=0.15):\n    height, width = binary.shape\n    for compo in compos:\n        if compo.height / height > block_side_length and compo.width / width > block_side_length:\n            clip = compo.compo_clipping(binary)\n            if is_block(clip):\n                compo.category = 'Block'\n# take the binary image as input\n# calculate the connected regions -> get the bounding boundaries of them -> check if those regions are rectangles\n# return all boundaries and boundaries of rectangles\ndef component_detection(binary, min_obj_area,\n                        line_thickness=C.THRESHOLD_LINE_THICKNESS,\n                        min_rec_evenness=C.THRESHOLD_REC_MIN_EVENNESS,\n                        max_dent_ratio=C.THRESHOLD_REC_MAX_DENT_RATIO,\n                        step_h = 5, step_v = 2,\n                        rec_detect=False, show=False, test=False):",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:533-556"
    },
    "115": {
        "file_id": 7,
        "content": "The code performs component detection on a binary image, calculating connected regions and bounding boundaries. It checks if the regions are rectangles to return all boundaries and rectangle boundaries. The function also categorizes components as blocks if they meet certain conditions.",
        "type": "comment"
    },
    "116": {
        "file_id": 7,
        "content": "    \"\"\"\n    :param binary: Binary image from pre-processing\n    :param min_obj_area: If not pass then ignore the small object\n    :param min_obj_perimeter: If not pass then ignore the small object\n    :param line_thickness: If not pass then ignore the slim object\n    :param min_rec_evenness: If not pass then this object cannot be rectangular\n    :param max_dent_ratio: If not pass then this object cannot be rectangular\n    :return: boundary: [top, bottom, left, right]\n                        -> up, bottom: list of (column_index, min/max row border)\n                        -> left, right: list of (row_index, min/max column border) detect range of each row\n    \"\"\"\n    mask = np.zeros((binary.shape[0] + 2, binary.shape[1] + 2), dtype=np.uint8)\n    compos_all = []\n    compos_rec = []\n    compos_nonrec = []\n    row, column = binary.shape[0], binary.shape[1]\n    for i in range(0, row, step_h):\n        for j in range(i % 2, column, step_v):\n            if binary[i, j] == 255 and mask[i, j] == 0:\n                # get connected area",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:557-576"
    },
    "117": {
        "file_id": 7,
        "content": "This function takes binary image, min/max object size and shape parameters, and returns the boundaries of detected components. It initializes a mask for each connected area and iterates through each row and column of the binary image to find non-zero pixels and add them to their respective lists.",
        "type": "comment"
    },
    "118": {
        "file_id": 7,
        "content": "                # region = util.boundary_bfs_connected_area(binary, i, j, mask)\n                mask_copy = mask.copy()\n                ff = cv2.floodFill(binary, mask, (j, i), None, 0, 0, cv2.FLOODFILL_MASK_ONLY)\n                if ff[0] < min_obj_area: continue\n                mask_copy = mask - mask_copy\n                region = np.reshape(cv2.findNonZero(mask_copy[1:-1, 1:-1]), (-1, 2))\n                region = [(p[1], p[0]) for p in region]\n                # filter out some compos\n                component = Component(region, binary.shape)\n                # calculate the boundary of the connected area\n                # ignore small area\n                if component.width <= 3 or component.height <= 3:\n                    continue\n                # check if it is line by checking the length of edges\n                # if component.compo_is_line(line_thickness):\n                #     continue\n                if test:\n                    print('Area:%d' % (len(region)))\n                    draw.draw_boundary([component], binary.shape, show=True)",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:577-598"
    },
    "119": {
        "file_id": 7,
        "content": "This code snippet detects components in an image and filters out small regions. It uses flood filling to create a mask, then reshapes and filters the region to exclude small areas or potential lines. If `test` is set, it prints the area size and displays the boundary of each detected component.",
        "type": "comment"
    },
    "120": {
        "file_id": 7,
        "content": "                compos_all.append(component)\n                if rec_detect:\n                    # rectangle check\n                    if component.compo_is_rectangle(min_rec_evenness, max_dent_ratio):\n                        component.rect_ = True\n                        compos_rec.append(component)\n                    else:\n                        component.rect_ = False\n                        compos_nonrec.append(component)\n                if show:\n                    print('Area:%d' % (len(region)))\n                    draw.draw_boundary(compos_all, binary.shape, show=True)\n    # draw.draw_boundary(compos_all, binary.shape, show=True)\n    if rec_detect:\n        return compos_rec, compos_nonrec\n    else:\n        return compos_all\ndef nested_components_detection(grey, org, grad_thresh,\n                   show=False, write_path=None,\n                   step_h=10, step_v=10,\n                   line_thickness=C.THRESHOLD_LINE_THICKNESS,\n                   min_rec_evenness=C.THRESHOLD_REC_MIN_EVENNESS,\n                   max_dent_ratio=C.THRESHOLD_REC_MAX_DENT_RATIO):",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:600-627"
    },
    "121": {
        "file_id": 7,
        "content": "This code detects and classifies components as either rectangular or non-rectangular based on evenness and dent ratio. It appends these components to separate lists. If \"rec_detect\" is True, it returns the rectangular and non-rectangular components separately; otherwise, it returns all detected components. The function also allows for visualization of component boundaries if \"show\" is set to True.",
        "type": "comment"
    },
    "122": {
        "file_id": 7,
        "content": "    '''\n    :param grey: grey-scale of original image\n    :return: corners: list of [(top_left, bottom_right)]\n                        -> top_left: (column_min, row_min)\n                        -> bottom_right: (column_max, row_max)\n    '''\n    compos = []\n    mask = np.zeros((grey.shape[0]+2, grey.shape[1]+2), dtype=np.uint8)\n    broad = np.zeros((grey.shape[0], grey.shape[1], 3), dtype=np.uint8)\n    broad_all = broad.copy()\n    row, column = grey.shape[0], grey.shape[1]\n    for x in range(0, row, step_h):\n        for y in range(0, column, step_v):\n            if mask[x, y] == 0:\n                # region = flood_fill_bfs(grey, x, y, mask)\n                # flood fill algorithm to get background (layout block)\n                mask_copy = mask.copy()\n                ff = cv2.floodFill(grey, mask, (y, x), None, grad_thresh, grad_thresh, cv2.FLOODFILL_MASK_ONLY)\n                # ignore small regions\n                if ff[0] < 500: continue\n                mask_copy = mask - mask_copy\n                region = np.reshape(cv2.findNonZero(mask_copy[1:-1, 1:-1]), (-1, 2))",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:628-651"
    },
    "123": {
        "file_id": 7,
        "content": "This code uses a flood fill algorithm to detect components in an image. It iterates through the image, ignoring already detected areas and using the flood fill function from cv2 (OpenCV) library. The result is a list of regions of interest, each represented as (top_left, bottom_right) coordinates.",
        "type": "comment"
    },
    "124": {
        "file_id": 7,
        "content": "                region = [(p[1], p[0]) for p in region]\n                compo = Component(region, grey.shape)\n                # draw.draw_region(region, broad_all)\n                # if block.height < 40 and block.width < 40:\n                #     continue\n                if compo.height < 30:\n                    continue\n                # print(block.area / (row * column))\n                if compo.area / (row * column) > 0.9:\n                    continue\n                elif compo.area / (row * column) > 0.7:\n                    compo.redundant = True\n                # get the boundary of this region\n                # ignore lines\n                if compo.compo_is_line(line_thickness):\n                    continue\n                # ignore non-rectangle as blocks must be rectangular\n                if not compo.compo_is_rectangle(min_rec_evenness, max_dent_ratio):\n                    continue\n                # if block.height/row < min_block_height_ratio:\n                #     continue\n                compos.append(compo)",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:652-676"
    },
    "125": {
        "file_id": 7,
        "content": "This code detects and filters components from an image based on size, area, shape, and type. It checks if the component is a line or a rectangle and skips those that do not meet the criteria. The threshold values for area and height are set to continue or skip processing.",
        "type": "comment"
    },
    "126": {
        "file_id": 7,
        "content": "                # draw.draw_region(region, broad)\n    if write_path is not None:\n        cv2.imwrite(write_path, broad)\n    return compos",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_detection.py:677-682"
    },
    "127": {
        "file_id": 7,
        "content": "This code segment saves the \"broad\" image to a specified path if \"write_path\" is not None, and then returns the \"compos\" image.",
        "type": "comment"
    },
    "128": {
        "file_id": 8,
        "content": "/component_detection/lib_ip/ip_draw.py",
        "type": "filepath"
    },
    "129": {
        "file_id": 8,
        "content": "The `draw_line()` function is responsible for drawing lines and components' boundaries on an image, while the functions draw_region and draw_region_bin modify a board by coloring or marking specific points within a given region. If show is True, they display the modified board using cv2.imshow.",
        "type": "summary"
    },
    "130": {
        "file_id": 8,
        "content": "import cv2\nimport numpy as np\nfrom random import randint as rint\nfrom config.CONFIG_ZEXUI import Config\nC = Config()\ndef draw_bounding_box_class(org, components, color_map=C.COLOR, line=2, show=False, write_path=None, name='board'):\n    \"\"\"\n    Draw bounding box of components with their classes on the original image\n    :param org: original image\n    :param components: bbox [(column_min, row_min, column_max, row_max)]\n                    -> top_left: (column_min, row_min)\n                    -> bottom_right: (column_max, row_max)\n    :param color_map: colors mapping to different components\n    :param line: line thickness\n    :param compo_class: classes matching the corners of components\n    :param show: show or not\n    :return: labeled image\n    \"\"\"\n    board = org.copy()\n    for compo in components:\n        bbox = compo.put_bbox()\n        board = cv2.rectangle(board, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color_map[compo.category], line)\n        # board = cv2.putText(board, compo.category, (bbox[0]+5, bbox[1]+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_map[compo.category], 2)",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_draw.py:1-27"
    },
    "131": {
        "file_id": 8,
        "content": "This function, located at \"SingularGPT/component_detection/lib_ip/ip_draw.py\":0-26, takes an original image (org), components' bounding boxes (bbox), color mapping for different components (color_map), line thickness (line), component class labels (compo_class), and a show or not parameter. It then creates a copy of the original image (board) and draws bounding boxes around each component in the original image, using the provided colors and line thickness. Additionally, it can optionally write the component class labels on top of the corresponding bounding box. Finally, if show is set to True, it will display the labeled image.",
        "type": "comment"
    },
    "132": {
        "file_id": 8,
        "content": "    if show:\n        cv2.imshow(name, board)\n        cv2.waitKey(0)\n    if write_path is not None:\n        cv2.imwrite(write_path, board)\n    return board\ndef draw_bounding_box(org, components, color=(0, 255, 0), line=2,\n                      show=False, write_path=None, name='board', is_return=False, wait_key=0):\n    \"\"\"\n    Draw bounding box of components on the original image\n    :param org: original image\n    :param components: bbox [(column_min, row_min, column_max, row_max)]\n                    -> top_left: (column_min, row_min)\n                    -> bottom_right: (column_max, row_max)\n    :param color: line color\n    :param line: line thickness\n    :param show: show or not\n    :return: labeled image\n    \"\"\"\n    if not show and write_path is None and not is_return: return\n    board = org.copy()\n    for compo in components:\n        bbox = compo.put_bbox()\n        board = cv2.rectangle(board, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, line)\n    if show:\n        cv2.imshow(name, board)\n        if wait_key is not None:",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_draw.py:28-56"
    },
    "133": {
        "file_id": 8,
        "content": "This code draws bounding boxes on an original image based on given component coordinates. It accepts the original image, component bboxes, color, line thickness, show flag, write path, name for image, is_return flag, and wait key. If the 'show' flag is True, it displays the labeled image with bounding boxes using OpenCV's imshow function. If 'write_path' is not None, it saves the labeled image to the specified file path using imwrite. The function returns the board image which can be useful for further processing if needed.",
        "type": "comment"
    },
    "134": {
        "file_id": 8,
        "content": "            cv2.waitKey(wait_key)\n        if wait_key == 0:\n            cv2.destroyWindow(name)\n    if write_path is not None:\n        # board = cv2.resize(board, (1080, 1920))\n        # board = board[100:-110]\n        cv2.imwrite(write_path, board)\n    return board\ndef draw_line(org, lines, color=(0, 255, 0), show=False):\n    \"\"\"\n    Draw detected lines on the original image\n    :param org: original image\n    :param lines: [line_h, line_v]\n            -> line_h: horizontal {'head':(column_min, row), 'end':(column_max, row), 'thickness':int)\n            -> line_v: vertical {'head':(column, row_min), 'end':(column, row_max), 'thickness':int}\n    :param color: drawn color\n    :param show: show or not\n    :return: image with lines drawn\n    \"\"\"\n    board = org.copy()\n    line_h, line_v = lines\n    for line in line_h:\n        cv2.line(board, tuple(line['head']), tuple(line['end']), color, line['thickness'])\n    for line in line_v:\n        cv2.line(board, tuple(line['head']), tuple(line['end']), color, line['thickness'])",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_draw.py:57-83"
    },
    "135": {
        "file_id": 8,
        "content": "The code snippet is a part of the function `draw_line()` that draws detected lines on the original image. It takes in an original image (`org`), list of lines (`lines`), color for drawing (`color`) and boolean flag (`show`) as inputs, and returns an image with lines drawn. The code iterates over each line in `line_h` and `line_v`, extracting the head and end points of each line. Then, it uses the cv2 library's `cv2.line()` function to draw the lines on a copy of the original image (`board`) with specified color and thickness. If `show` is set to True, the drawn image is displayed using `cv2.waitKey()`. Additionally, there's an optional write path (`write_path`) where the drawn image can be saved as a new file using `cv2.imwrite()`, but only if it is not None.",
        "type": "comment"
    },
    "136": {
        "file_id": 8,
        "content": "    if show:\n        cv2.imshow('img', board)\n        cv2.waitKey(0)\n    return board\ndef draw_boundary(components, shape, show=False):\n    \"\"\"\n    Draw boundary of objects on the black withe\n    :param components: boundary: [top, bottom, left, right]\n                        -> up, bottom: (column_index, min/max row border)\n                        -> left, right: (row_index, min/max column border) detect range of each row\n    :param shape: shape or original image\n    :param show: show or not\n    :return: drawn board\n    \"\"\"\n    board = np.zeros(shape[:2], dtype=np.uint8)  # binary board\n    for component in components:\n        # up and bottom: (column_index, min/max row border)\n        for point in component.boundary[0] + component.boundary[1]:\n            board[point[1], point[0]] = 255\n        # left, right: (row_index, min/max column border)\n        for point in component.boundary[2] + component.boundary[3]:\n            board[point[0], point[1]] = 255\n    if show:\n        cv2.imshow('rec', board)\n        cv2.waitKey(0)",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_draw.py:84-110"
    },
    "137": {
        "file_id": 8,
        "content": "This function takes a set of components and draws their boundaries on an image, returning the resulting board. It also provides the option to display the drawn board using OpenCV functions. The code initializes a binary board of zeros, then iterates through each component's boundary points, setting them to white in the board array. Finally, if 'show' is set to True, it displays the drawn board as an image.",
        "type": "comment"
    },
    "138": {
        "file_id": 8,
        "content": "    return board\ndef draw_region(region, broad, show=False):\n    color = (rint(0,255), rint(0,255), rint(0,255))\n    for point in region:\n        broad[point[0], point[1]] = color\n    if show:\n        cv2.imshow('region', broad)\n        cv2.waitKey()\n    return broad\ndef draw_region_bin(region, broad, show=False):\n    for point in region:\n        broad[point[0], point[1]] = 255\n    if show:\n        cv2.imshow('region', broad)\n        cv2.waitKey()\n    return broad",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_draw.py:111-132"
    },
    "139": {
        "file_id": 8,
        "content": "The code defines two functions: draw_region and draw_region_bin. Both functions take a region, board, and optional show parameter. They modify the board by coloring or marking specific points within the given region. If show is True, they display the modified board with cv2.imshow.",
        "type": "comment"
    },
    "140": {
        "file_id": 9,
        "content": "/component_detection/lib_ip/ip_preprocessing.py",
        "type": "filepath"
    },
    "141": {
        "file_id": 9,
        "content": "The code is a Python script for image preprocessing, including resizing, grayscaling, median blurring, and gradient map conversion. It also includes functions for filtering, binarization, and display or saving of the processed image with optional parameters.",
        "type": "summary"
    },
    "142": {
        "file_id": 9,
        "content": "import cv2\nimport numpy as np\nfrom config.CONFIG_ZEXUI import Config\nC = Config()\ndef read_img(path, resize_height=None, kernel_size=None):\n    def resize_by_height(org):\n        w_h_ratio = org.shape[1] / org.shape[0]\n        resize_w = resize_height * w_h_ratio\n        re = cv2.resize(org, (int(resize_w), int(resize_height)))\n        return re\n    try:\n        img = cv2.imread(path)\n        if kernel_size is not None:\n            img = cv2.medianBlur(img, kernel_size)\n        if img is None:\n            print(\"*** Image does not exist ***\")\n            return None, None\n        if resize_height is not None:\n            img = resize_by_height(img)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        return img, gray\n    except Exception as e:\n        print(e)\n        print(\"*** Img Reading Failed ***\\n\")\n        return None, None\ndef gray_to_gradient(img):\n    if len(img.shape) == 3:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_f = np.copy(img)\n    img_f = img_f.astype(\"float\")\n    kernel_h = np.array([[0,0,0], [0,-1.,1.], [0,0,0]])",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_preprocessing.py:1-39"
    },
    "143": {
        "file_id": 9,
        "content": "The code is a Python script for image preprocessing. It reads an input image, applies resizing and gray-scaling transformations, and can optionally apply median blurring. The function \"gray_to_gradient\" converts grayscale images to gradient maps.",
        "type": "comment"
    },
    "144": {
        "file_id": 9,
        "content": "    kernel_v = np.array([[0,0,0], [0,-1.,0], [0,1.,0]])\n    dst1 = abs(cv2.filter2D(img_f, -1, kernel_h))\n    dst2 = abs(cv2.filter2D(img_f, -1, kernel_v))\n    gradient = (dst1 + dst2).astype('uint8')\n    return gradient\ndef reverse_binary(bin, show=False):\n    \"\"\"\n    Reverse the input binary image\n    \"\"\"\n    r, bin = cv2.threshold(bin, 1, 255, cv2.THRESH_BINARY_INV)\n    if show:\n        cv2.imshow('binary_rev', bin)\n        cv2.waitKey()\n    return bin\ndef binarization(org, grad_min, show=False, write_path=None, wait_key=0):\n    grey = cv2.cvtColor(org, cv2.COLOR_BGR2GRAY)\n    grad = gray_to_gradient(grey)        # get RoI with high gradient\n    rec, binary = cv2.threshold(grad, grad_min, 255, cv2.THRESH_BINARY)    # enhance the RoI\n    morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, (3, 3))  # remove noises\n    if write_path is not None:\n        cv2.imwrite(write_path, morph)\n    if show:\n        cv2.imshow('binary', morph)\n        if wait_key is not None:\n            cv2.waitKey(wait_key)\n    return morph",
        "type": "code",
        "location": "/component_detection/lib_ip/ip_preprocessing.py:40-69"
    },
    "145": {
        "file_id": 9,
        "content": "The code consists of three functions: `ip_preprocessing.py` includes a function that performs image filtering and calculates the gradient, another that reverses binary images, and a final one for binarization (converting an image to black and white) based on a given minimum gradient value. The binarized image can be displayed or saved to a specified file path with optional parameters for customization.",
        "type": "comment"
    },
    "146": {
        "file_id": 10,
        "content": "/config/CONFIG.py",
        "type": "filepath"
    },
    "147": {
        "file_id": 10,
        "content": "This code imports necessary modules and defines platform-specific settings. It supports Linux, Windows, and potentially Android platforms. The OCR component can be Paddle or Google Vision, but the final decision is not yet made in this snippet. There are empty lists for Component Classifications and x11 settings, which may hold additional information.",
        "type": "summary"
    },
    "148": {
        "file_id": 10,
        "content": "from os.path import join as pjoin\nimport os\n_PLATFORM = 'windows'\n# _PLATFORM = 'linux'\n# _PLATFORM_ENV = 'COLAB'\n# _PLATFORM_ENV = 'NON_COLAB'\n_OCR = 'paddle' \n# _OCR = 'google-vision'\n# Todo\n_SUPPORTED_PLATFORMS = ['linux', 'windows', 'Android']\n_COMPONENTS_CLASSIFICATIONS = []\n#### x11 settings ###",
        "type": "code",
        "location": "/config/CONFIG.py:1-21"
    },
    "149": {
        "file_id": 10,
        "content": "This code imports necessary modules and defines platform-specific settings. It supports Linux, Windows, and potentially Android platforms. The OCR component can be Paddle or Google Vision, but the final decision is not yet made in this snippet. There are empty lists for Component Classifications and x11 settings, which may hold additional information.",
        "type": "comment"
    },
    "150": {
        "file_id": 11,
        "content": "/config/CONFIG_ZEXUI.py",
        "type": "filepath"
    },
    "151": {
        "file_id": 11,
        "content": "The code includes a Config class with adjustable threshold values for object recognition, line detection, scaling, text analysis, and UI element classification. It also defines a dictionary named \"COLOR\" that maps different UI components to their respective colors for visual representation in the ZEXUI system.",
        "type": "summary"
    },
    "152": {
        "file_id": 11,
        "content": "class Config:\n    def __init__(self):\n        # Adjustable\n        # self.THRESHOLD_PRE_GRADIENT = 4             # dribbble:4 rico:4 web:1\n        # self.THRESHOLD_OBJ_MIN_AREA = 55            # bottom line 55 of small circle\n        # self.THRESHOLD_BLOCK_GRADIENT = 5\n        self.THRESHOLD_REC_MIN_EVENNESS = 0.7\n        self.THRESHOLD_REC_MAX_DENT_RATIO = 0.25\n        self.THRESHOLD_LINE_THICKNESS = 8\n        self.THRESHOLD_LINE_MIN_LENGTH = 0.95\n        self.THRESHOLD_COMPO_MAX_SCALE = (0.25, 0.98)  \n        self.THRESHOLD_TEXT_MAX_WORD_GAP = 10\n        self.THRESHOLD_TEXT_MAX_HEIGHT = 0.04 \n        self.THRESHOLD_TOP_BOTTOM_BAR = (0.045, 0.94)  \n        self.THRESHOLD_BLOCK_MIN_HEIGHT = 0.03  \n        self.CLASS_MAP = {'0':'Button', '1':'CheckBox', '2':'Chronometer', '3':'EditText', '4':'ImageButton', '5':'ImageView',\n               '6':'ProgressBar', '7':'RadioButton', '8':'RatingBar', '9':'SeekBar', '10':'Spinner', '11':'Switch',\n               '12':'ToggleButton', '13':'VideoView', '14':'TextView'}",
        "type": "code",
        "location": "/config/CONFIG_ZEXUI.py:1-22"
    },
    "153": {
        "file_id": 11,
        "content": "The code defines a Config class with adjustable threshold values and a class map. The threshold values are related to object recognition, line detection, composition scaling, text analysis, and UI element classification. These values can be modified for better performance or customization in the ZEXUI system.",
        "type": "comment"
    },
    "154": {
        "file_id": 11,
        "content": "        self.COLOR = {'Button': (0, 255, 0), 'CheckBox': (0, 0, 255), 'Chronometer': (255, 166, 166),\n                      'EditText': (255, 166, 0),\n                      'ImageButton': (77, 77, 255), 'ImageView': (255, 0, 166), 'ProgressBar': (166, 0, 255),\n                      'RadioButton': (166, 166, 166),\n                      'RatingBar': (0, 166, 255), 'SeekBar': (0, 166, 10), 'Spinner': (50, 21, 255),\n                      'Switch': (80, 166, 66), 'ToggleButton': (0, 66, 80), 'VideoView': (88, 66, 0),\n                      'TextView': (169, 255, 0),\n                      'Text':(169, 255, 0), 'Non-Text':(255, 0, 166),\n                      'Noise':(6,6,255), 'Non-Noise': (6,255,6),\n                      'Image':(255,6,6), 'Non-Image':(6,6,255)}",
        "type": "code",
        "location": "/config/CONFIG_ZEXUI.py:24-36"
    },
    "155": {
        "file_id": 11,
        "content": "This code defines a dictionary named \"COLOR\" where each key represents a different UI component and its corresponding color value. It maps various user interface elements to their respective colors for visual representation in the application.",
        "type": "comment"
    },
    "156": {
        "file_id": 12,
        "content": "/example_generated_script.py",
        "type": "filepath"
    },
    "157": {
        "file_id": 12,
        "content": "Code interacts with the ZexUI library to perform actions on a document. It writes text, waits for specified durations, clicks images, and moves the mouse cursor. It finds and clicks an image labeled \"zx_1.PNG\" and finally closes the document.",
        "type": "summary"
    },
    "158": {
        "file_id": 12,
        "content": "from zexui_lib.zexui import ZexUI\nfrom time import sleep\nzex = ZexUI()\nzex.text('Writer Document').click()\nsleep(4)\nzex.write('Hello, i am SingularGPT developed by @abhiprojectz.')\nsleep(3)\nzex.write('Now, i will find the icon you specified, and click on it for you :)')\nzex.image('/content/zx_1.PNG').click()\nsleep(3)\nzex.write('Have, you seen?')\nzex.write('Now. i will close it.')\nzex.mouseMoveTo('center')\nzex.image('/content/zx_1.PNG').click()",
        "type": "code",
        "location": "/example_generated_script.py:1-17"
    },
    "159": {
        "file_id": 12,
        "content": "Code interacts with the ZexUI library to perform actions on a document. It writes text, waits for specified durations, clicks images, and moves the mouse cursor. It finds and clicks an image labeled \"zx_1.PNG\" and finally closes the document.",
        "type": "comment"
    },
    "160": {
        "file_id": 13,
        "content": "/instructions_lib/fetch_commands.py",
        "type": "filepath"
    },
    "161": {
        "file_id": 13,
        "content": "This function loads the prompt from a file named \"prompts.txt\" and returns its content as a string. The file is located two folders up, and the function reads it in UTF-8 encoding mode.",
        "type": "summary"
    },
    "162": {
        "file_id": 13,
        "content": "# Save your prompts on the main prompts.txt file, try to describe as brief as you can.\ndef load_prompt():\n    with open('../prompts.txt', 'r', encoding='utf-8') as f:\n        data = f.read()\n    return data",
        "type": "code",
        "location": "/instructions_lib/fetch_commands.py:1-6"
    },
    "163": {
        "file_id": 13,
        "content": "This function loads the prompt from a file named \"prompts.txt\" and returns its content as a string. The file is located two folders up, and the function reads it in UTF-8 encoding mode.",
        "type": "comment"
    },
    "164": {
        "file_id": 14,
        "content": "/instructions_lib/generate_commands.py",
        "type": "filepath"
    },
    "165": {
        "file_id": 14,
        "content": "The code imports necessary libraries, initializes the OpenAI API with an API key, sets the endpoint, and has a `request` method. It defines a function that generates completions for a given prompt using the OpenAI API, checks required parameters, sets request parameters, and prints/returns the response.",
        "type": "summary"
    },
    "166": {
        "file_id": 14,
        "content": "import requests\nimport json\nfrom dotenv import load_dotenv\nimport os\nfrom instructions_lib.fetch_commands import load_prompt \nfrom instructions_lib.process_instructions import generate_script, execute_commands \nload_dotenv()\nclass OpenAI_API:\n    def __init__(self, api_key):\n        self.api_key = api_key\n        self.endpoint = 'https://api.openai.com/v1/'\n    def request(self, path, params=None):\n        headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self.api_key}',\n            'User-Agent': 'OpenAI API Client'\n        }\n        url = self.endpoint + path\n        try:\n            response = requests.post(url, headers=headers, json=params)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            raise Exception(f'Error: {err}')\n        return response.json()\n    def completions(self, prompt, model, temperature=0.5, max_tokens=50):\n        path = 'completions'\n        params = {\n            'model': model,\n            'prompt': prompt,",
        "type": "code",
        "location": "/instructions_lib/generate_commands.py:1-37"
    },
    "167": {
        "file_id": 14,
        "content": "This code imports necessary libraries and defines the `OpenAI_API` class. It initializes an instance of this class with an API key, sets the OpenAI API endpoint, and has a method called `request` for making requests to the OpenAI API. The `completions` method takes a prompt, model, temperature, and maximum number of tokens as parameters and makes a request to the OpenAI API's completions endpoint.",
        "type": "comment"
    },
    "168": {
        "file_id": 14,
        "content": "            'temperature': temperature,\n            'max_tokens': max_tokens\n        }\n        return self.request(path, params)\ndef generate(prompt):\n    if prompt:\n        prompt = load_prompt()\n    api_key = os.getenv('OPENAI_API') \n    openai = OpenAI_API(api_key)\n    response = openai.completions(prompt, 'text-davinci-002', temperature=0.7, max_tokens=100)\n    print(response)\n    return response",
        "type": "code",
        "location": "/instructions_lib/generate_commands.py:38-51"
    },
    "169": {
        "file_id": 14,
        "content": "This code defines a function that uses the OpenAI API to generate completions for a given prompt. It first checks if the prompt is provided, then initializes the OpenAI API with an environment variable API key and sets the parameters for the completion request. Finally, it makes the request to the API and prints and returns the response.",
        "type": "comment"
    },
    "170": {
        "file_id": 15,
        "content": "/instructions_lib/process_instructions.py",
        "type": "filepath"
    },
    "171": {
        "file_id": 15,
        "content": "The code imports necessary modules, defines a Jinja2 template for ZexUI instructions, obtains the current directory and its parent directory's path. It generates a script using the template and writes it to the parent directory's file \"script.py\". The execute_commands function is defined but left empty in this code snippet.",
        "type": "summary"
    },
    "172": {
        "file_id": 15,
        "content": "import os\nfrom jinja2 import Template\n# Need to implement a semantic syntax matcher that purifies the GPT generated commands response \n_ZEXUI_INSTRUCTIONS_TEMPLATE = Template(\"\"\"from ZexUI.zexui import ZexUI\nzex = ZexUI()\n{{ _code }}\n\"\"\")\n# current directory\nlocation = os.path.dirname(os.path.realpath(__file__))\n# Get the path of the parent directory (i.e., one level up)\nparent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n# Construct the path to the file to be written in the parent directory\nfile_path = os.path.join(parent_dir, 'script.py')\ndef generate_script(_code):\n    print(location)\n    with open(file_path, 'w', encoding='utf-8') as f:\n        _content = _ZEXUI_INSTRUCTIONS_TEMPLATE.render(_code=_code)\n        data = f.write(_content)\n    print(\"[Automation script has been generated.]\")\ndef execute_commands(_code):\n    pass",
        "type": "code",
        "location": "/instructions_lib/process_instructions.py:1-30"
    },
    "173": {
        "file_id": 15,
        "content": "The code imports necessary modules, defines a Jinja2 template for ZexUI instructions, obtains the current directory and its parent directory's path. It generates a script using the template and writes it to the parent directory's file \"script.py\". The execute_commands function is defined but left empty in this code snippet.",
        "type": "comment"
    },
    "174": {
        "file_id": 16,
        "content": "/libs_installation.sh",
        "type": "filepath"
    },
    "175": {
        "file_id": 16,
        "content": "Installing required libraries and tools for image processing using apt package manager with elevated privileges.",
        "type": "summary"
    },
    "176": {
        "file_id": 16,
        "content": "#!/bin/bash \nsudo apt install scrot xvfb xorg xserver-xorg scrot imagemagick x11-utils xdotool imagemagick",
        "type": "code",
        "location": "/libs_installation.sh:1-3"
    },
    "177": {
        "file_id": 16,
        "content": "Installing required libraries and tools for image processing using apt package manager with elevated privileges.",
        "type": "comment"
    },
    "178": {
        "file_id": 17,
        "content": "/main.py",
        "type": "filepath"
    },
    "179": {
        "file_id": 17,
        "content": "The code imports functions from two different libraries, generates commands based on a prompt, generates a script from those commands, and then runs the script using subprocess. It also has an unused execute_commands function call at the end.",
        "type": "summary"
    },
    "180": {
        "file_id": 17,
        "content": "from instructions_lib.generate_commands import generate, execute_commands\nfrom instructions_lib.process_instructions import generate_script, execute_commands \nimport subprocess \n_prompt = 'Query: click on the item with text \"Document Writer\" after that click on the image with path \"image.png\" after that scroll down and then find element that is top of text \"File\" , double left click it.'\ncommands = generate(_prompt)\ngenerate_script(commands)\nsubprocess.run('python script.py', shell=True)\n# execute_commands(commands)",
        "type": "code",
        "location": "/main.py:1-14"
    },
    "181": {
        "file_id": 17,
        "content": "The code imports functions from two different libraries, generates commands based on a prompt, generates a script from those commands, and then runs the script using subprocess. It also has an unused execute_commands function call at the end.",
        "type": "comment"
    },
    "182": {
        "file_id": 18,
        "content": "/requirements.txt",
        "type": "filepath"
    },
    "183": {
        "file_id": 18,
        "content": "The code represents a list of dependencies for a Python project. These include: PaddleOCR for optical character recognition, OpenCV for image processing, Google Cloud Vision API client, NumPy for numerical computations, Matplotlib for data visualization, Xlib for interface with the X Window System, and PyVirtualDisplay for running virtual displays.",
        "type": "summary"
    },
    "184": {
        "file_id": 18,
        "content": "paddleocr\nopencv-python-headless\ngoogle-cloud-vision\nnumpy\nmatplotlib\npython-xlib\npyvirtualdisplay",
        "type": "code",
        "location": "/requirements.txt:1-7"
    },
    "185": {
        "file_id": 18,
        "content": "The code represents a list of dependencies for a Python project. These include: PaddleOCR for optical character recognition, OpenCV for image processing, Google Cloud Vision API client, NumPy for numerical computations, Matplotlib for data visualization, Xlib for interface with the X Window System, and PyVirtualDisplay for running virtual displays.",
        "type": "comment"
    },
    "186": {
        "file_id": 19,
        "content": "/script.py",
        "type": "filepath"
    },
    "187": {
        "file_id": 19,
        "content": "The code is importing the ZexUI module from zexui_lib and creating an instance of it named \"zex\". The script then uses this instance to click on an image named \"tx_5.PNG\" located at \"C:\\Users\\abhis\\Desktop\\\", though scrolling down may be required beforehand, followed by finding the text 'File' and double-left clicking on it using the zex instance.",
        "type": "summary"
    },
    "188": {
        "file_id": 19,
        "content": "from zexui_lib.zexui import ZexUI\n# import zexui_lib.zexui\nzex = ZexUI()\n# zex.text('Document Writer').click()\nzex.image(r\"C:\\\\Users\\\\abhis\\\\Desktop\\\\tx_5.PNG\").click()\n# scroll_down()\n# zex.text('File').findTopOf().mouseDoubleLeftClick()",
        "type": "code",
        "location": "/script.py:1-7"
    },
    "189": {
        "file_id": 19,
        "content": "The code is importing the ZexUI module from zexui_lib and creating an instance of it named \"zex\". The script then uses this instance to click on an image named \"tx_5.PNG\" located at \"C:\\Users\\abhis\\Desktop\\\", though scrolling down may be required beforehand, followed by finding the text 'File' and double-left clicking on it using the zex instance.",
        "type": "comment"
    },
    "190": {
        "file_id": 20,
        "content": "/text_detection/Text.py",
        "type": "filepath"
    },
    "191": {
        "file_id": 20,
        "content": "The `Text` class represents text elements with properties and methods for justification and merging. The code initializes word width based on content length, detects text location using a binary map, and visualizes the text as a rectangle on an image.",
        "type": "summary"
    },
    "192": {
        "file_id": 20,
        "content": "import cv2\nimport numpy as np\nclass Text:\n    def __init__(self, id, content, location):\n        self.id = id\n        self.content = content\n        self.location = location\n        self.width = self.location['right'] - self.location['left']\n        self.height = self.location['bottom'] - self.location['top']\n        self.area = self.width * self.height\n        self.word_width = self.width / len(self.content)\n    '''\n    ********************************\n    *** Relation with Other text ***\n    ********************************\n    '''\n    def is_justified(self, ele_b, direction='h', max_bias_justify=4):\n        '''\n        Check if the element is justified\n        :param max_bias_justify: maximum bias if two elements to be justified\n        :param direction:\n             - 'v': vertical up-down connection\n             - 'h': horizontal left-right connection\n        '''\n        l_a = self.location\n        l_b = ele_b.location\n        # connected vertically - up and below\n        if direction == 'v':\n            # left and right should be justified",
        "type": "code",
        "location": "/text_detection/Text.py:1-33"
    },
    "193": {
        "file_id": 20,
        "content": "The class `Text` represents a text with its id, content, location, width, height, and area. It has a method `is_justified` that checks if an element is justified based on the maximum bias for justification, direction (vertical or horizontal), and location of another element `ele_b`.",
        "type": "comment"
    },
    "194": {
        "file_id": 20,
        "content": "            if abs(l_a['left'] - l_b['left']) < max_bias_justify and abs(l_a['right'] - l_b['right']) < max_bias_justify:\n                return True\n            return False\n        elif direction == 'h':\n            # top and bottom should be justified\n            if abs(l_a['top'] - l_b['top']) < max_bias_justify and abs(l_a['bottom'] - l_b['bottom']) < max_bias_justify:\n                return True\n            return False\n    def is_on_same_line(self, text_b, direction='h', bias_gap=4, bias_justify=4):\n        '''\n        Check if the element is on the same row(direction='h') or column(direction='v') with ele_b\n        :param direction:\n             - 'v': vertical up-down connection\n             - 'h': horizontal left-right connection\n        :return:\n        '''\n        l_a = self.location\n        l_b = text_b.location\n        # connected vertically - up and below\n        if direction == 'v':\n            # left and right should be justified\n            if self.is_justified(text_b, direction='v', max_bias_justify=bias_justify):",
        "type": "code",
        "location": "/text_detection/Text.py:34-56"
    },
    "195": {
        "file_id": 20,
        "content": "This code checks if two text elements are on the same row (horizontal) or column (vertical) by comparing their positions and justification. It returns True if they meet the criteria, otherwise False.",
        "type": "comment"
    },
    "196": {
        "file_id": 20,
        "content": "                # top and bottom should be connected (small gap)\n                if abs(l_a['bottom'] - l_b['top']) < bias_gap or abs(l_a['top'] - l_b['bottom']) < bias_gap:\n                    return True\n            return False\n        elif direction == 'h':\n            # top and bottom should be justified\n            if self.is_justified(text_b, direction='h', max_bias_justify=bias_justify):\n                # top and bottom should be connected (small gap)\n                if abs(l_a['right'] - l_b['left']) < bias_gap or abs(l_a['left'] - l_b['right']) < bias_gap:\n                    return True\n            return False\n    def is_intersected(self, text_b, bias):\n        l_a = self.location\n        l_b = text_b.location\n        left_in = max(l_a['left'], l_b['left']) + bias\n        top_in = max(l_a['top'], l_b['top']) + bias\n        right_in = min(l_a['right'], l_b['right'])\n        bottom_in = min(l_a['bottom'], l_b['bottom'])\n        w_in = max(0, right_in - left_in)\n        h_in = max(0, bottom_in - top_in)",
        "type": "code",
        "location": "/text_detection/Text.py:57-78"
    },
    "197": {
        "file_id": 20,
        "content": "This code compares the positions of two text boxes, checking for overlap and alignment in both horizontal (h) and vertical (v) directions. If there is an overlap or proper justification in either direction, it returns True; otherwise, False. The is_intersected function uses these checks to determine if two text boxes intersect or not.",
        "type": "comment"
    },
    "198": {
        "file_id": 20,
        "content": "        area_in = w_in * h_in\n        if area_in > 0:\n            return True\n    '''\n    ***********************\n    *** Revise the Text ***\n    ***********************\n    '''\n    def merge_text(self, text_b):\n        text_a = self\n        top = min(text_a.location['top'], text_b.location['top'])\n        left = min(text_a.location['left'], text_b.location['left'])\n        right = max(text_a.location['right'], text_b.location['right'])\n        bottom = max(text_a.location['bottom'], text_b.location['bottom'])\n        self.location = {'left': left, 'top': top, 'right': right, 'bottom': bottom}\n        self.width = self.location['right'] - self.location['left']\n        self.height = self.location['bottom'] - self.location['top']\n        self.area = self.width * self.height\n        left_element = text_a\n        right_element = text_b\n        if text_a.location['left'] > text_b.location['left']:\n            left_element = text_b\n            right_element = text_a\n        self.content = left_element.content + ' ' + right_element.content",
        "type": "code",
        "location": "/text_detection/Text.py:79-104"
    },
    "199": {
        "file_id": 20,
        "content": "This code defines a method `merge_text` that takes another `Text` object, compares their positions, and merges them into one by updating the location, width, height, and area attributes. The method also combines the contents of both texts into a single string.",
        "type": "comment"
    }
}